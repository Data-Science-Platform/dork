#!/bin/bash

if [ -z "$SPARK_PORT_DRIVER" ] || [ -z "$SPARK_PORT_FILESERVER" ] || [ -z "$SPARK_PORT_BROADCAST" ] || [ -z "$SPARK_PORT_REPL_CLASS_SERVER" ] || [ -z "$SPARK_PORT_BLOCK_MANAGER" ] || [ -z "$SPARK_PORT_EXECUTOR" ] || [ -z "$SPARK_MASTER_IP" ] || [ -z "$SPARK_MASTER_PORT" ] || [ -z "$SPARK_MASTER_WEBUI_PORT" ] || [ -z "$SPARK_LOCAL_IP" ] || [ -z "$SPARK_USER_NAME" ] || [ -z "$SPARK_USER_ID" ] || [ -z "$SPARK_GROUP_NAME" ] || [ -z "$SPARK_GROUP_ID" ]
then
  echo "Please set all required environment variables."
  exit 1
fi

setup-users

export SPARK_MASTER_OPTS="-Dspark.driver.port=$SPARK_PORT_DRIVER \
-Dspark.fileserver.port=$SPARK_PORT_FILESERVER \
-Dspark.broadcast.port=$SPARK_PORT_BROADCAST \
-Dspark.replClassServer.port=$SPARK_PORT_REPL_CLASS_SERVER \
-Dspark.blockManager.port=$SPARK_PORT_BLOCK_MANAGER \
-Dspark.executor.port=$SPARK_PORT_EXECUTOR \
-Dspark.broadcast.factory=org.apache.spark.broadcast.HttpBroadcastFactory"


if [ "$SPARK_MASTER_RECOVERY_DIRECTORY" ]
then
  if [ -d "$SPARK_MASTER_RECOVERY_DIRECTORY" ]
  then
    export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=FILESYSTEM -Dspark.deploy.recoveryDirectory=$SPARK_MASTER_RECOVERY_DIRECTORY"
    chown -R $SPARK_USER_NAME $SPARK_MASTER_RECOVERY_DIRECTORY
    chgrp -R $SPARK_GROUP_NAME $SPARK_MASTER_RECOVERY_DIRECTORY
  else
    echo "SPARK_MASTER_RECOVERY_DIRECTORY=$SPARK_MASTER_RECOVERY_DIRECTORY is not a directory"
    exit 1
  fi
fi

# Edit Spark master options to write event logs
if [ "$SPARK_EVENT_LOG_DIR" ]
then
  if [ -d "$SPARK_EVENT_LOG_DIR" ]
  then
    echo "Configuring master server to write logs to '$SPARK_EVENT_LOG_DIR'"
    export SPARK_DEFAULTS_FILE=$SPARK_HOME/conf/spark-defaults.conf
    touch $SPARK_DEFAULTS_FILE
    echo "spark.eventLog.enabled true" >> $SPARK_DEFAULTS_FILE
    echo "spark.eventLog.dir $SPARK_EVENT_LOG_DIR" >> $SPARK_DEFAULTS_FILE
  else
    echo "SPARK_EVENT_LOG_DIR=$SPARK_EVENT_LOG_DIR is defined but is not a directory"
    exit 1
  fi
fi

echo "SPARK_MASTER_OPTS" $SPARK_MASTER_OPTS
echo "SPARK_DAEMON_JAVA_OPTS" $SPARK_DAEMON_JAVA_OPTS

chown -R $SPARK_USER_NAME $SPARK_HOME
chgrp -R $SPARK_GROUP_NAME $SPARK_HOME

exec sudo -E -u $SPARK_USER_NAME $SPARK_HOME/bin/spark-class org.apache.spark.deploy.master.Master \
    --ip $SPARK_MASTER_IP \
    --port $SPARK_MASTER_PORT \
    --webui-port $SPARK_MASTER_WEBUI_PORT \
    "$@"

