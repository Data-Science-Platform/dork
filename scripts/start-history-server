#!/bin/bash

if [ -z "$SPARK_USER_NAME" ] || [ -z "$SPARK_USER_ID" ] || [ -z "$SPARK_GROUP_NAME" ] || [ -z "$SPARK_GROUP_ID" ] || [ -z "$SPARK_EVENT_LOG_DIR" ] || [ -z "$SPARK_HISTORY_SERVER_PORT" ] || [ -z "$SPARK_HISTORY_SERVER_UPDATE_INTERVAL" ] || [ -z "$SPARK_HISTORY_SERVER_MAX_DISK_USAGE" ]
then
  echo "Please set all required environment variables."
  exit 1
fi

setup-users

if [ "$SPARK_EVENT_LOG_DIR" ]
then
  if [ -d "$SPARK_EVENT_LOG_DIR" ]
  then
    echo "Configuring history server to read from '$SPARK_EVENT_LOG_DIR'"
  else
    echo "SPARK_EVENT_LOG_DIR=$SPARK_EVENT_LOG_DIR is defined but is not a directory"
    exit 1
  fi
fi

chown -R $SPARK_USER_NAME:$SPARK_GROUP_NAME $SPARK_HOME
chown -R $SPARK_USER_NAME:$SPARK_GROUP_NAME $SPARK_EVENT_LOG_DIR

export SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=$SPARK_EVENT_LOG_DIR \
-Dspark.history.fs.update.interval=$SPARK_HISTORY_SERVER_UPDATE_INTERVAL \
-Dspark.history.ui.port=$SPARK_HISTORY_SERVER_PORT \
-Dspark.history.store.maxDiskUsage=$SPARK_HISTORY_SERVER_MAX_DISK_USAGE"

if [ -n "$SPARK_HISTORY_SERVER_CLEANER_MAX_AGE" ]
then
   export SPARK_HISTORY_OPTS="-Dspark.history.fs.cleaner.enabled=true -Dspark.history.fs.cleaner.maxAge=$SPARK_HISTORY_SERVER_CLEANER_MAX_AGE "$SPARK_HISTORY_OPTS
fi

echo "SPARK_HISTORY_OPTS" $SPARK_HISTORY_OPTS

. "${SPARK_HOME}/sbin/spark-config.sh"
. "${SPARK_HOME}/bin/load-spark-env.sh"

exec sudo -E -u $SPARK_USER_NAME $SPARK_HOME/bin/spark-class org.apache.spark.deploy.history.HistoryServer "$@"

