#!/bin/bash

if [ -z "$SPARK_USER_NAME" ] || [ -z "$SPARK_USER_ID" ] || [ -z "$SPARK_GROUP_NAME" ] || [ -z "$SPARK_GROUP_ID" ] || [ -z "$SPARK_EVENT_LOG_DIR" ] || [ -z "$SPARK_HISTORY_SERVER_PORT" ] || [ -z "$SPARK_HISTORY_SERVER_UPDATE_INTERVAL" ] || [ -z "$SPARK_HISTORY_SERVER_MAX_DISK_USAGE" ]
then
  echo "Please set all required environment variables."
  exit 1
fi

setup-users

if [ ! "$SPARK_EVENT_LOG_DIR" ]
    echo "SPARK_EVENT_LOG_DIR is not defined "
    exit 1
fi

chown -R $SPARK_USER_NAME:$SPARK_GROUP_NAME $SPARK_HOME
chown -R $SPARK_USER_NAME:$SPARK_GROUP_NAME $SPARK_EVENT_LOG_DIR

export SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=$SPARK_EVENT_LOG_DIR \
-Dspark.history.fs.update.interval=$SPARK_HISTORY_SERVER_UPDATE_INTERVAL \
-Dspark.history.ui.port=$SPARK_HISTORY_SERVER_PORT \
-Dspark.history.store.maxDiskUsage=$SPARK_HISTORY_SERVER_MAX_DISK_USAGE"

if [ -n "$SPARK_HISTORY_SERVER_CLEANER_MAX_AGE" ]
then
   export SPARK_HISTORY_OPTS="-Dspark.history.fs.cleaner.enabled=true -Dspark.history.fs.cleaner.maxAge=$SPARK_HISTORY_SERVER_CLEANER_MAX_AGE "$SPARK_HISTORY_OPTS
fi

echo "SPARK_HISTORY_OPTS" $SPARK_HISTORY_OPTS

. "${SPARK_HOME}/sbin/spark-config.sh"
. "${SPARK_HOME}/bin/load-spark-env.sh"

exec sudo -E -u $SPARK_USER_NAME $SPARK_HOME/bin/spark-class org.apache.spark.deploy.history.HistoryServer "$@"

